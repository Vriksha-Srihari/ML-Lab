{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pcn              #using perceptron network\n",
    "import kmeans           # and kmeans clustering algorithm\n",
    "\n",
    "class rbf:\n",
    "    \n",
    "\n",
    "    def __init__(self,inputs,targets,nRBF,sigma=0,usekmeans=0,normalise=0):\n",
    "        self.nin = np.shape(inputs)[1]\n",
    "        self.nout = np.shape(targets)[1]\n",
    "        self.ndata = np.shape(inputs)[0]\n",
    "        self.nRBF = nRBF\n",
    "        self.usekmeans = usekmeans\n",
    "        self.normalise = normalise\n",
    "        \n",
    "        if usekmeans:\n",
    "            self.kmeansnet = kmeans.kmeans(self.nRBF,inputs)\n",
    "            \n",
    "        self.hidden = np.zeros((self.ndata,self.nRBF+1))\n",
    "        \n",
    "        if sigma==0:\n",
    "            # Set width of Gaussians\n",
    "            d = (inputs.max(axis=0)-inputs.min(axis=0)).max()\n",
    "            self.sigma = d/np.sqrt(2*nRBF)  \n",
    "        else:\n",
    "            self.sigma = sigma\n",
    "                \n",
    "        self.perceptron = pcn.pcn(self.hidden[:,:-1],targets)\n",
    "        \n",
    "        # Initialise network\n",
    "        self.weights1 = np.zeros((self.nin,self.nRBF))\n",
    "        \n",
    "    def rbftrain(self,inputs,targets,eta=0.25,niterations=100):\n",
    "        if self.usekmeans==0:\n",
    "            # Version 1: set RBFs to be datapoints\n",
    "            indices = range(self.ndata)\n",
    "            np.random.shuffle(indices)\n",
    "            for i in range(self.nRBF):\n",
    "                self.weights1[:,i] = inputs[indices[i],:]\n",
    "        else:\n",
    "            # Version 2: use k-means\n",
    "            self.weights1 = np.transpose(self.kmeansnet.kmeanstrain(inputs))\n",
    "\n",
    "        for i in range(self.nRBF):\n",
    "            self.hidden[:,i] = np.exp(-np.sum((inputs - np.ones((1,self.nin))*self.weights1[:,i])**2,axis=1)/(2*self.sigma**2))\n",
    "        if self.normalise:\n",
    "            self.hidden[:,:-1] /= np.transpose(np.ones((1,np.shape(self.hidden)[0]))*self.hidden[:,:-1].sum(axis=1))\n",
    "        \n",
    "        # Call Perceptron without bias node (since it adds its own)\n",
    "        self.perceptron.pcntrain(self.hidden[:,:-1],targets,eta,niterations)\n",
    "        \n",
    "    def rbffwd(self,inputs):\n",
    "\n",
    "        hidden = np.zeros((np.shape(inputs)[0],self.nRBF+1))\n",
    "\n",
    "        for i in range(self.nRBF):\n",
    "            hidden[:,i] = np.exp(-np.sum((inputs - np.ones((1,self.nin))*self.weights1[:,i])**2,axis=1)/(2*self.sigma**2))\n",
    "\n",
    "        if self.normalise:\n",
    "            hidden[:,:-1] /= np.transpose(np.ones((1,np.shape(hidden)[0]))*hidden[:,:-1].sum(axis=1))\n",
    "        \n",
    "        # Add the bias\n",
    "        hidden[:,-1] = -1\n",
    "        outputs = self.perceptron.pcnfwd(hidden)\n",
    "        return outputs\n",
    "    \n",
    "    def confmat(self,inputs,targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        outputs = self.rbffwd(inputs)\n",
    "        nClasses = np.shape(targets)[1]\n",
    "\n",
    "        if nClasses==1:\n",
    "            nClasses = 2\n",
    "            outputs = np.where(outputs>0,1,0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs,1)\n",
    "            targets = np.argmax(targets,1)\n",
    "\n",
    "        cm = np.zeros((nClasses,nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i,j] = np.sum(np.where(outputs==i,1,0)*np.where(targets==j,1,0))\n",
    "\n",
    "        output = cm\n",
    "        print(\"Confusion matrix is:\")\n",
    "        print(cm)\n",
    "        print(\"Percentage Correct: \", np.trace(cm) / np.sum(cm) * 100)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49880026  0.61144219 -0.25438505  0.20451374  0.        ]\n",
      " [ 0.64342405  0.56622605 -0.23328978 -0.07427406  0.        ]\n",
      " [ 0.53704115 -0.4135054   0.03185603  0.3565094   0.        ]\n",
      " [ 0.47298296  0.68911749 -0.32721727 -0.6598847   0.        ]\n",
      " [-0.01635021 -0.57824013  0.19202762  0.05571211  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "iris = np.loadtxt('banknote.csv',delimiter=',')\n",
    "iris[:,:4] = iris[:,:4]-iris[:,:4].mean(axis=0)\n",
    "imax = np.concatenate((iris.max(axis=0)*np.ones((1,5)),iris.min(axis=0)*np.ones((1,5))),axis=0).max(axis=0)\n",
    "iris[:,:4] = iris[:,:4]/imax[:4]\n",
    "print (iris[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1372, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nindices = np.where(iris[:,9]==2)\\ntarget[indices,2] = 1\\nindices = np.where(iris[:,9]==3) \\ntarget[indices,0] = 1\\nindices = np.where(iris[:,9]==4)\\ntarget[indices,1] = 1\\nindices = np.where(iris[:,9]==5)\\ntarget[indices,2] = 1\\nindices = np.where(iris[:,9]==5)\\ntarget[indices,2] = 1\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = np.zeros((np.shape(iris)[0], 2))\n",
    "indices = np.where(iris[:,4]==0) \n",
    "target[indices,0] = 1\n",
    "indices = np.where(iris[:,4]==1)\n",
    "target[indices,1] = 1\n",
    "'''\n",
    "indices = np.where(iris[:,9]==2)\n",
    "target[indices,2] = 1\n",
    "indices = np.where(iris[:,9]==3) \n",
    "target[indices,0] = 1\n",
    "indices = np.where(iris[:,9]==4)\n",
    "target[indices,1] = 1\n",
    "indices = np.where(iris[:,9]==5)\n",
    "target[indices,2] = 1\n",
    "indices = np.where(iris[:,9]==5)\n",
    "target[indices,2] = 1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.arange(np.shape(iris)[0])\n",
    "np.random.shuffle(order)\n",
    "iris = iris[order,:]\n",
    "target = target[order,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = iris[::2,0:4]\n",
    "traint = target[::2]\n",
    "valid = iris[1::4,0:4]\n",
    "validt = target[1::4]\n",
    "test = iris[3::4,0:4]\n",
    "testt = target[3::4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.] [-1.16973236 -1.42307569 -0.40284444 -1.83464881]\n"
     ]
    }
   ],
   "source": [
    "print (train.max(axis=0), train.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:-\n",
      "Confusion matrix is:\n",
      "[[363. 110.]\n",
      " [  5. 208.]]\n",
      "Percentage Correct:  83.23615160349854\n",
      "Test data:-\n",
      "Confusion matrix is:\n",
      "[[186.  53.]\n",
      " [  5.  99.]]\n",
      "Percentage Correct:  83.09037900874635\n"
     ]
    }
   ],
   "source": [
    "net = rbf(train,traint,5,1,1)\n",
    "\n",
    "net.rbftrain(train,traint,0.25,5000)\n",
    "print(\"Train data:-\")\n",
    "net.confmat(train,traint)\n",
    "print(\"Test data:-\")\n",
    "cm = net.confmat(test,testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[186.,  53.],\n",
       "       [  5.,  99.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGjCAYAAADKC9ToAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZyVZf3/8dewLwozbILi7vd3iVJ+NS3XNJcKNZdEcc/1m1uKipKpIW6pYZKGZd+fv3BLzbTUIrPELRNcUJHtEhQQSTZhcAHZ5vz+OGdgZjwwZ+AMZ+by9fQxj/G+7+vc58Ie5vvx+VzXfZdlMhkkSZJS1aLUE5AkSWpMhh1JkpQ0w44kSUqaYUeSJCXNsCNJkpJm2JEkSUlrVeoJrFjwnnvfpY3sgt0Hl3oK0pfWXTMeKduY31fM/8627rbdRp17sVjZkSRJSSt5ZUeSJDWiqlWlnkHJGXYkSUpZpqrUMyg521iSJClpVnYkSUpZlZUdw44kSQnL2MayjSVJktJmZUeSpJTZxjLsSJKUNNtYtrEkSVLarOxIkpQyHypo2JEkKWm2sWxjSZKktFnZkSQpZe7GMuxIkpQyHypoG0uSJCXOyo4kSSkrURsrhLADMAjYE+gLTIkx9q0zJrOOW+wVYxyTG/ccsH+eMXvEGF+rby6GHUmSUla6NtbOwGHAWLKdpHzdpL3ynLsN2A6oG2JeIhueappcyEQMO5IkqTE8GWN8HCCEMBLYve6A6spNtRBCObAr8NsY48o6wyvrji+UYUeSpJSV6KGCMcb1KSkdC7QF7i/mXAw7kiSlrHntxjoZeCfG+Eqea/uHED4lm11eA4bEGJ8p5KaGHUmSVJBcm6k8z6XKGGPlBt57K2A/4Jo8l58H7gOmApsBA4GnQwiHxBhH13dvw44kSSkr7m6sgcCQPOeHkj+kNMSJQBl5WlgxxlrfGUJ4Angr952GHUmSvtSK28YaDozMc36Dqjo5JwEvxxjfq29gjHFZCOFx4IJCbmzYkSRJBcm1qooRbGoJIfw32WfxnN+Aj5UVOtCwI0lSyprHu7FOAlYADxcyOITQFjgSeLWQ8YYdSZISlsmUZut5CKEDcGjucGugUwihf+741RjjzNy4FsAJwFMxxo/y3Gc/4DLgT8AMoCdwEdkHD/6wkLkYdiRJUmPoATxS51z18emsWftzALAFcMla7vMh0Aa4EegKLAHGAAfEGF8qZCKGHUmSUlai5+zEGGdQwLqa3NbxtY6LMU4DvrshczHsSJKUsuaxZqdRGXYkSUpZ83qCcqPI9wZSSZKkZFjZkSQpZSV6EWhTYtiRJClltrFsY0mSpLRZ2ZEkKWXuxjLsSJKUNNtYtrEkSVLarOxIkpQy21iGHUmSkmbYsY0lSZLSZmVHkqSEZTI+VNCwI0lSymxj2caSJElps7IjSVLKfM6OYUeSpKTZxrKNJUmS0mZlR5KklNnGMuxIkpQ021i2sSRJUtqs7EiSlDLbWIYdSZKSZhvLNpYkSUqblR1JklJmZcewI0lS0lyzYxtLkiSlzcqOJEkps41l2JEkKWm2sWxjSZKktFnZkSQpZbaxDDuSJCXNNpZtLEmSlDYrO5Ikpcw2lmFHkqSkGXZsY0mSpLRZ2ZEkKWWZTKlnUHKGHUmSUmYbyzaWJElKm5UdSZJSZmXHsCNJUtJK9FDBEMIOwCBgT6AvMCXG2LfOmJHAD/J8/NgY4x/rjB0EnA/0BCYCg2OMzxQyF9tYkiSpMewMHAZMAyatY9x7wF51fkbXHJALOjcCI3L3nAr8NYSwSyETsbIjSVLKStfGejLG+DisruDsvpZxS2OMY9Z2kxBCW+AqYHiMcVju3PPA28CVwHH1TcTKjiRJKctkivfTADHGYqWsvYHOwEM17r0K+APQL4RQVt8NrOxIkqSChBDKgfI8lypjjJXredvtQwiVQEdgAnBTjPHhGtf75H5PrvO5icAmwBbAB+v6Ais7kiSlrKqqeD8wEJie52fges7uDbKLmI8C+pMNLQ+FEE6rMaYCWBZjXFrns4tyv7vU9yVWdiRJSllx1+wMB0bmOb9eVZ0Y4y/rnHo8hDAauLbO9+TroZWt41othh1JklSQXKtqfdtVhXoEuDOE0D3GOJ9sBaddCKFdjPHzGuOq22mLvnCHOgw7kiSlrETP2dkAdRccV6/V6UO27VVtJ+ATYHZ9NzTsSJKUsExV83kRaG5n1bHAzFxVB+DfwGJgALmwE0JoSXbL+VMxRttYkiRp4wshdAAOzR1uDXQKIfTPHb+a+30P8CDZBw+WA2cBBwCnVN8nxrgshHA9cGMIYT4wLjdue+DEQuZi2JEkKWWle6hgD7Lrb2qqPj4deIJsxeaq3NgVZIPMETHGJ2t+KMY4LIQAcCGwGdlt54fFGN8qZCKGHUmSUlaiNTsxxhl8cf1NXUc24H7DgGHrMxefsyNJkpJmZUeSpJQ1owXKjcWwI0lSykq3ZqfJMOxIkpQyw45rdiRJUtqs7EiSlLKMa3YMOwl57c23Gfn7R5kUpzFvwUdc/5NLOOqwQ9b5maeeeYH/vfdhZs6aTUV5Z0445nuccVL/dX5mQy3++BN+Nvw3PPevMQAcsO+e/OTic+m06SYAvDJuPPc9/Cfenhz59NMlbNm7F6ccdxTfP/w7jTovqSk5fOCxfG/gcbXOLZ5fyeV7nA3AEZcM4GuH7UVFr66sXLGSWROm8/itD/HeuHdKMV01ZbaxDDspWbJkKTtstw1H9DuIn1x3a73jX3z5VQYPvZkrBp7LPt/4Gu/NnMU1N/2Sdm3bcGL/I9Z7HqddcDlH9TtkrUFr8NBb+HDOPH5963WUlZUx5GfDueK6nzPilqEAvPn2JP5r+204/aT+dO/ahZdeeZ2ht9xO2zZtOOzb31rveUnNzZx3Z3Pr8desPq5ateY/WnPf+w8PXv1/WTBrHq3bteHgMw/nwnuu5OpvXcgnCxaXYLZS02XYScg39/4639z76wBcecMv6h3/5N9Hs/8+3+D47x8OwJZb9OKsU47j7gce4YRjvkdZWfZZUM/9awx3/r8HmDZ9Jt27duHQQw7gvDNOonXr1g2e47sz3udfY17j3l8PY9ev7ATAkMt/xKnnXcb0mR+w7da9+Z8fHF/rM8cffTivjhvPP557ybCjL5VVK1fx8fz8L5ge++cXax0/cv097Hv8QWy50zZMeqGgh8rqy8Kt54WFnRBCH6AfsCPQBciQfaX6FGBUjHFKo81QjWb58hW0bdOm1rm2bdsyd94C/jNnHlv02oyXxr7O4KG38OOB5/C1XfoyZ+58rv35HSxfsYLLLji7wd/51oTJdGjffnXQAdj1qzvTvn073pwwiW237p33c59+toTNundr8PdJzVn3rTbjpjF3sWrFSqa/OZU/3/J7Fsya94VxLVu3Yr8TDmbpx0uYNWnGxp+omrbm99bzolvnbqwQQvsQwu+BCcANwN5k30nRK/f3NwATQwgPhBDaNfZkVVz7fGM3Rr/wMi+NfZ2qqipmvP8B9zz0GADzP1oIwG/veYjTT+zP0Yd9m616b87Xv7YLF593Bn/48ygy67HobcFHi+hS0Xl11QigrKyMrhXlLPhoUd7PPPfSWMa+9ibHHtlvPf6UUvM0/c2pjBw0gjtOu4H7fvwbOnUv5/LHbqBj+Sarx3zlwN345cT7+FV8gIPOPJzhp1xnC0vKo77Kzs3AIcDJwKMxxuU1L4YQ2gDfB27Pjb2oMSapxtH/iH7Mmv0hF/74WlauWknHDh04+bijuPPu+2nZIpuDJ8WpvD05cvcDa97llqnK8PmyZSz4aBHdu3Vh6C138JenR6++vmzZcsZPnMINt925+twT999Fr5491jqXTCZTKwBVGzd+IoOvuZkfX3wOX9kpFOOPLTULE597s9bx9Demcv0Lv2KvYw7gn3f/BYD48kSuP/QyNumyKfsefzBnj7iYm4++cq2tL31J2caqN+wcD1wcY3ww38Vc+HkohNAauBXDTrNSVlbGJeedyUU/PI0FCxfRpbwzY17L/h/s5r02A6CqKsO5p5/Edw7c7wufryjvDMAFZ5/C6Sces/r84KG3cMgB+3Dw/vusPte9W1cAunWtYOGixbXCTSaTYWHlYrp2Ka91/3FvTeDcQT/lgrNO4fijDy/in1xqfpYt+ZwPp86ix7a9Vp9bvnQZ82fOYf7MOUx/YyrXPns7+x5/EKPueLSEM1VTk3E3Vr1hpz0wt4D7zM2NVTPUsmXL1ethRv3zeXbp24euFdng0SfswPSZs9iq9+Zr/XzXivLV4wHatm1Dl/LyvJ/ZpW8flixdypsTJq9et/PmhMksXfo5/913zTqe1958m/MGDeG8M0/ilAFHF+XPKTVnrdq2puf2WxBfnrjWMS1alNG6TcM3Dkipqy/svAT8NITwWowx74KKEEIFcDXwYr7r2niWLFnK+x/8B8i2mj6cO48p77xL506b0qtnD2779e+YMDly9+03AbCocjF/f/ZF9tj1q6xYvoI/jfoHT49+kZEjbll9z3NPP5HzLxvC5j178J2DvknLli2Z9t4M3p70Dpeef2aD57j9Nlux7567c+0td3DN4AvJANfecgf77/P11YuTXxk3nvMv+ykDjj6cw7/9LRbk1g+1aNGCLhXl67i7lI5jfnIK4595nYWzF7Bpt04c9qP+tGnflpcffY52m7TnOz88kreeeY3F8yrZtEsnDjj1O5T37Mprf/13qaeupsY2Vr1h5wLgOeD9EMIzwCSgkuxurAqgD3BQ7tyBjTdNFWLClKmc8aPBq49H3H0/I+6+nyP7HcwNV13Kgo8WMmv2h7U+8+TfnuHWEXdDJsMuffvwu1/dXGttzD7f+Bojfj6Uu0Y+yMgHH6NlyxZsvWVvjjr04PWe581DLufG237N/1x8JZB9qOCVl5y3+vrjo/7B0s+XMfLBRxn54Jpy/OY9e/D0o/es9/dKzUlFr66cdftFbFLRiU8Wfsz0N97h5qOvZOHsBbRu14Ze/2dL9j7uW3Qs35TPKj9hxvh3GTbgp8ye8n6pp66mxt1YlNW3oyaE0Bk4h+zW8z5kQw5kt55PBkYBd8UY12sLwIoF7xk5pY3sgt0H1z9IUqO4a8YjX9yN0Yg+u/7kov13tuNV92/UuRdLvc/ZyYWYm3M/kiSpObGN5ROUJUlKmrux1v1QQUmSpObOyo4kSSmzjWXYkSQpae7Gso0lSZLSZmVHkqSU2cYy7EiSlDLfjWUbS5IkJc7KjiRJKbONZdiRJClphh3bWJIkKW1WdiRJSpnP2THsSJKUNNtYtrEkSVLarOxIkpSwjJUdw44kSUkz7NjGkiRJabOyI0lSynxdhGFHkqSk2cayjSVJktJmZUeSpJRZ2THsSJKUskymNGEnhLADMAjYE+gLTIkx9q1xvSVwKXAYsDPQEngLGBJjfL7OvWYAW+f5mu4xxgX1zcU2liRJagw7kw0y04BJea63B64AxgE/AE4AFgKjQwgH5xn/R2CvOj+VhUzEyo4kSSkrXRvryRjj4wAhhJHA7nWuLwW2izEuqj4RQvgHMAG4CPhnnfFzY4xj1mcihh1JklJWorATY1znnvcY4ypgUd1zIYTxwDbFnIthR5IkNQkhhFZk1/iMznP5pBDCWcAq4F/AFTHGcYXc17AjSVLCivlurBBCOVCe51JljLGg9TP1uBzoDfymzvkngLHA+2QXKl8BvBhC2CPGmG89UC2GHUmSUlbcNtZAYEie80OBazbkxiGEQ3L3uSHGOLbmtRjjhTUOXwwh/A2YAvwYOLW+ext2JElSoYYDI/Oc36CqTghhN+BR4EHyh6laYowfhRBGA18r5P6GHUmSUlbEV2PlWlXFaFetlnsez9+AfwNnxhgLLUWVFfodhh1JkhJWzDU7xRZC6AU8TXYtTv8Y44oCP9cNOBD4SyHjDTuSJKnoQggdgENzh1sDnUII/XPHrwLzyFZ0upF9rk7fEMLqz1c/UyeEcAJweG7sbLLb0gcDbYGbCpmLYUeSpJSVrrLTA3ikzrnq49OB54BdcsdP5Pl8dZtqOrA58AugAlgMPE+2EjSlkIkYdiRJSlkR1+w0RIxxBvWvq6l33U2uwvOtDZmL78aSJElJs7IjSVLCmvIC5Y3FsCNJUspK1MZqSmxjSZKkpFnZkSQpYbaxDDuSJKXNNpZhR5KklGUMO67ZkSRJabOyI0lSyqzsGHYkSUqZbSzbWJIkKXFWdiRJSpmVHcOOJEkps41lG0uSJCXOyo4kSQmzsmPYkSQpaYYd21iSJClxVnYkSUpZpqzUMyg5w44kSQmzjWUbS5IkJc7KjiRJCctU2cYy7EiSlDDbWLaxJElS4qzsSJKUsIy7sQw7kiSlzDaWbSxJkpQ4KzuSJCXM3ViGHUmSkpbJlHoGpWcbS5IkJc3KjiRJCbONZdiRJClphh3bWJIkKXFWdiRJSpgLlA07kiQlzTaWbSxJkpQ4KzuSJCXMd2MZdiRJSprvxrKNJUmSEmdlR5KkhFXZxjLsSJKUMtfsGHYkSVIjCCHsAAwC9gT6AlNijH3zjOsH3ADsBMwGhscY78gzbhBwPtATmAgMjjE+U8hcXLMjSVLCMlVlRftpoJ2Bw4BpwKR8A0IIewJPAG8A/YDfAcNDCOfUGTcIuBEYkbvnVOCvIYRdCpmIlR1JkhJWwicoPxljfBwghDAS2D3PmCHAuBjjmbnjZ0MIWwFDQgi/jTFWhRDaAleRrfgMy93veeBt4ErguPomYmVHkiQVXYxxnZvecyHmQODhOpd+T7ZVtVvueG+gM/BQjXuvAv4A9Ash1FtyMuxIkpSwErax6rM90IYvtrgm5n7vmPvdJ/d7cp5xmwBb1PdFtrEkSUpYMbeehxDKgfI8lypjjJUNvF1F9WfrnF+U+92lxrhlMcal6xj3wbq+yMqOJEkq1EBgep6fgRtwz7WtKsrUM6ZsHddqsbIjSVLCivycneHAyDznG1rVgTWVmYo65yvqXF8EtAshtIsxfl5jXHmdcWtl2JEkKWHF3I2Va1WtT7DJ511gOdk1OU/VOL9T7veU3O/qtTp9yG5RrznuE7LP5lkn21iSJGmjizEuA0bzxa3jJwBzgHG5438Di4EB1QNCCC1zn3sqxmgbS5KkL7NSvRsrhNABODR3uDXQKYTQP3f8aoxxJnAt8EII4X+BB4B9gLOB86u3rscYl4UQrgduDCHMJxuCziK7m+vEQuZi2JEkKWElfDdWD+CROueqj08HRsYYXw4hHEn26cinAv8BLo4x/qbmh2KMw0IIABcCm5Hddn5YjPGtQiZi2JEkSUUXY5zBmh1T6xo3ChhVwLhhwLD1mYthR5KkhJXwdRFNhmFHkqSElWrNTlNS8rDTfvP9Sj0F6Utn3Oa71T9IkhJR8rAjSZIaTwkXKDcZhh1JkhJmG8uHCkqSpMRZ2ZEkKWFuxjLsSJKUNNtYhh1JkpLmAmXX7EiSpMRZ2ZEkKWFVpZ5AE2DYkSQpYZn6X0+VPNtYkiQpaVZ2JElKWJV7zw07kiSlrMo2lm0sSZKUNis7kiQlzAXKhh1JkpLm1nPbWJIkKXFWdiRJSphtLMOOJElJs41lG0uSJCXOyo4kSQmzsmPYkSQpaa7ZsY0lSZISZ2VHkqSEVVnYMexIkpQy341lG0uSJCXOyo4kSQnLlHoCTYBhR5KkhLn13DaWJElKnJUdSZISVlXmAmXDjiRJCXPNjm0sSZKUOCs7kiQlzAXKhh1JkpLmE5RtY0mSpMRZ2ZEkKWG+LsKwI0lS0tyNZRtLkiQlzsqOJEkJK9UC5RDCc8D+a7l8RYzxphDCNcCQPNcvizEOK9ZcDDuSJCWshFvPzwM61Tl3Su78qBrnlgIH1hk3s5gTMexIkqSiizFOqnsuhHA78HaMcXyN01UxxjGNORfX7EiSlLBMEX82RAjhv4A9gPs38FYNZmVHkqSEFXPNTgihHCjPc6kyxlhZz8dPJttV+32d8+1DCPOALsA04I4Y44gNnmwNVnYkSVKhBgLT8/wMLOCzJwLPxxg/qHFuGjAYOAE4AngZ+FVu4XLRWNmRJClhRV6gPBwYmef8Oqs6IYQ9gR2An9U8H2Os29IaFUIAGBxC+HmM8bP1n+oahh1JkhJWzLCTa1XV167K52Tgc+CPBYz9A3AasBPw6np81xfYxpIkSY0mhNAKOA54Msb4cQEfKfqTgazsSJKUsEzpX431HaA7he/CGkD22TsTizUBw44kSQkr4UMFq50MfAT8re6FEMLrwD1ABNqQDTonAVfFGJcUawKGHUmS1ChCCJuQ3WV1T4xxRZ4h08ju5OqVO54InBFj/F0x52HYkSQpYaWs7MQYPwU6ruP6gI0xD8OOJEkJ29AnH6fA3ViSJClpVnYkSUpYMV8X0VwZdiRJSlgT2I1VcraxJElS0qzsSJKUMCs7hh1JkpLmbizbWJIkKXFWdiRJSpi7sQw7kiQlzTU7hh1JkpLmmh3X7EiSpMRZ2ZEkKWFV1nYMO5Ikpcw1O7axJElS4qzsSJKUMJtYhh1JkpJmG8s2liRJSpyVHUmSEuYTlA07kiQlza3ntrEkSVLirOxIkpQw6zqGHUmSkuZuLNtYkiQpcVZ2JElKmAuUDTuSJCXNqGMbS5IkJc7KjiRJCXOBsmFHkqSkuWbHNpYkSUqclR1JkhJmXcewI0lS0lyzYxtLkiQlzsqOJEkJy9jIMuxIkpQy21i2sSRJUuKs7EiSlDCfs2PYkSQpaUYd21iSJClxVnbUID+9+hJ+evWltc7NmTOP3lvtWqIZSelq0bE9m116Ep2/vRetunVm6cT3+M/Q/2Xp+KkAtOpWTs8fn8am+/03LTttwmevTGD2kLtYPuPDEs9cTUmp2lghhNOA3+W5NCLGeEGNcf2AG4CdgNnA8BjjHcWci2FHDTYlTuOgg/uvPl61alUJZyOlq/fNP6Ldjtswa9BtrPjwIyqOPoDt7r+OeMh5rJy7kK1/eyVUVTHjf26g6pMldDvrKLa7/3riIeeRWbqs1NNXE9EEdmN9F1hc43hO9d+EEPYEngDuBS4F9gGGhxBWxBh/U6wJFC3shBC2Ag6IMd5brHuqaVq5ciVz584v9TSkpJW1bUPn7+7NzHN/xmdjJgAwd/iDbHrQ1+l68qEsemw0HXfbkXf6/YjPJ88AYPaVd7LTq/dSccT+LHz46RLOXqrl9RjjgrVcGwKMizGemTt+NpcnhoQQfhtjLEpWK+aanT3IX65SYrbbdmtmTn+NqfFlHrj/TrbddqtST0lKTlmrlpS1aknVsuW1zmc+X07HPXaiRZvW2eNlK2pczFC1fAUd9thpY05VTVymiH8VUwihLXAg8HCdS78HegK7Feu7XKCsBnnllTc446yLOfyIUzjn3MvpuVl3Xnz+cbp0qSj11KSkVH22lM9en8xmFwyg1WZdoEULyo86gA67BVp3r+Dzdz9g+Qdz6XnZqbTsvAllrVvR/ZxjaLN5d1r38N9HrVFVxJ/1NCGEsCqEMD2EMCSEUN1V2h5oA0yqM35i7veO6/+VtdXbxgohjC/wXp02cC5qBp76+7O1jseMfZ2p8WVOPeVYhv/ytyWalZSmWRf/gt4/v4idxt5DZuUqlk54l8onXqB93+1h5SpmnvMzet9yITu/9SCZlav49KU3+fjZ10o9bSUshFAOlOe5VBljrKxz7kOybapXgFVAP+BqYFvgNKA6ldf93KLc7y5FmDJQ2JqdPmRT1hv1jNsa2HKDZ6Rm5bPPljBp0jvssMO2pZ6KlJzl78/hvQFXUNa+LS036cDK+YvY6leXs3zWXACWTniXqYdeRItNO1DWuhWrFn7MDn8expLx00o8czUlRW4/DSQbYOoaClxT80SM8e/A32uc+kcIYTFwTQjhulpTzK9oEy8k7EwApsYYT1/XoBDCMcD+RZmVmo22bdsSwvY89/xLpZ6KlKzM0mWsXLqMlp06suk3d+XDn42sdb3qkyUAtNmmF+2/sgNzbn2gBLNUU1Xk3VjDgZF5ztetzqzNH8iGot1Y066q23etPl5EkRQSdsaSLT0VomwD5qJm4JabruYvf/0H78+aTY/u3bjyJwPp2LED9973SKmnJiVnk2/uSlmLFnw+7QPabtOLXj85nWXvzWbhI/8EoPOh+7By0ces+GAe7Xbchs2HnM3HT4/l0xfrK8RL6yfXqio02ORTMye8Cywn20F6qsb56hX2Uzbge2opJOz8HBhVwLhRZPtwStgWvXtx/30j6NatC/Pnf8TYV8axz37f4/33Z5d6alJyWm7akZ6Xn0rrnt1YtfgTFv/t38wZdh+szD7bqlWPLvS66kxadStn5bxFLHpsNPPuqLuxRV92VZkm9cKIAWTbU6/HGJeFEEYDxwG31RhzAtln8Ywr1peWZUr8D6FVmy2a1P8K0pfBuM2LtqNTUgN9dcaTG7ULcvLW3y/af2fvn/lYwXMPIfwdGE12OUwV2S7RecDvYoxn58bsBbxAtjX2ANmHCl4LnN8kHyooSZJUw2TgDKA32bwxFRhMdt0PADHGl0MIRwI3AqcC/wEuLmbQAcOOJElJK9W7sWKMA8nu3qpv3CgKWy6z3gw7kiQlrNhPPm6OfIKyJElKmpUdSZIS1gTeel5yhh1JkhJWqjU7TYltLEmSlDQrO5IkJcwFyoYdSZKS5pod21iSJClxVnYkSUpYqV8L1RQYdiRJSpi7sWxjSZKkxFnZkSQpYS5QNuxIkpQ0t54bdiRJSpprdlyzI0mSEmdlR5KkhLn13LAjSVLSXKBsG0uSJCXOyo4kSQlzN5ZhR5KkpLkbyzaWJElKnJUdSZIS5m4sw44kSUmzjWUbS5IkJc7KjiRJCXM3lmFHkqSkVblmxzaWJElKm5UdSZISZl3HsCNJUtLcjWUbS5IkJc7KjiRJCbOyY9iRJClpPkHZNpYkSUqclR1JkhJmG8uwI0lS0nyCsm0sSZKUOCs7kiQlzAXKhh1JkpLmmh3bWJIkKXFWdiRJSphtLMOOJElJK1UbK4RwLHASsDtQAUwD7gDujjFmcmNGAj/I8/FjY4x/LNZcDDuSJKkxXALMAC4F5gOHAHcBWwJDaox7j2woqgbq+ykAAASCSURBVOmdYk7EsCNJUsJK+Jyd78UYF9Q4Hh1C6AoMDCEMjTFW5c4vjTGOacyJuEBZkqSEVWUyRftpiDpBp9obQCegXTH+bIWysiNJkgoSQigHyvNcqowxVhZwi/2AGTHGJTXObR9CqAQ6AhOAm2KMD2/4bNewsiNJUsIyRfwLGAhMz/MzsL55hBD2BQYAI2qcfgMYBBwF9Ac+AB4KIZxWxH8EVnYkSUpZQ9tP9RgOjMxzfp1VnRBCb+Bh4HngturzMcZf1hn6eAhhNHDtWr5nvRh2JElSQXKtqkLaVavlWl9/AxYCR8cYV9XzkUeAO0MI3WOM89dvprUZdiRJSlgp33oeQmgP/AXoDOwVY1xcwMfKij0Pw44kSQkrchurYCGEVsAfgD7AfjHG2QV8pgw4FphZrKoOGHYkSVLjuBM4nOxDBTuFEPascW0S2acq3wM8SPbpyuXAWcABwCnFnIhhR5KkhJWwjfXt3O9b81z7FjAeWAxcBfQAVgDjgCNijE8WcyKGHUmSElaqNlaMcZsChh3Z2PMAn7MjSZISZ2VHkqSElXI3VlNh2JEkKWGZTFX9gxJnG0uSJCXNyo4kSQmrso1l2JEkKWWZEu3GakpsY0mSpKRZ2ZEkKWG2sQw7kiQlzTaWbSxJkpQ4KzuSJCWsVK+LaEoMO5IkJcwnKNvGkiRJibOyI0lSwlygbNiRJClpbj037EiSlDQrO67ZkSRJibOyI0lSwtx6btiRJClptrFsY0mSpMRZ2ZEkKWHuxjLsSJKUNNtYtrEkSVLirOxIkpQwd2MZdiRJSpovArWNJUmSEmdlR5KkhNnGMuxIkpQ0d2PZxpIkSYmzsiNJUsJcoGzYkSQpabaxbGNJkqTEWdmRJClhVnYMO5IkJc2oA2UmPkmSlDLX7EiSpKQZdiRJUtIMO5IkKWmGHUmSlDTDjiRJSpphR5IkJc2wI0mSkmbYkSRJSTPsSJKkpPm6CDVICOG/gDuAfYGlwEPA4BjjkpJOTEpcCGEHYBCwJ9AXmBJj7FvaWUnNg2FHBQshlAPPAjOB/kAP4BdAd+D4Ek5N+jLYGTgMGEu2Km9lXiqQ/7KoIX4IVABHxhifijHeC1wIDAgh7FzaqUnJezLGuGWMsT8wrtSTkZoTw44a4lDgmRjjghrnHgWWAf1KMyXpyyHGWFXqOUjNlWFHDdEHmFTzRIxxGfAusGNJZiRJUj0MO2qICqAyz/lFQJeNPBdJkgpi2FFDZfKcK1vLeUmSSs6wo4ZYRLa6U1d57pokSU2OYUcNMZnsup3VQghtge2BKSWZkSRJ9TDsqCFGAQeFELrWOHc00DZ3TZKkJqcsk3GphQqTe6jgBGAGcB1rHir4TIzRhwpKjSiE0IHs4x8AzidbUb0kd/xqjHFmSSYmNQM+QVkFizFWhhAOBG4HHmPN6yIuL+nEpC+HHsAjdc5VH58OjNyos5GaESs7kiQpaa7ZkSRJSTPsSJKkpBl2JElS0gw7kiQpaYYdSZKUNMOOJElKmmFHkiQlzbAjSZKSZtiRJElJ+//Q/yFpV+YjrAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = np.array(cm)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14})  # font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87       191\n",
      "           1       0.95      0.65      0.77       152\n",
      "\n",
      "    accuracy                           0.83       343\n",
      "   macro avg       0.87      0.81      0.82       343\n",
      "weighted avg       0.86      0.83      0.82       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "targets=testt\n",
    "inputs = test\n",
    "nClasses = np.shape(targets)[1]\n",
    "outputs = net.rbffwd(inputs)\n",
    "if nClasses==1:\n",
    "    nClasses = 2\n",
    "    outputs = np.where(outputs>0,1,0)\n",
    "else:\n",
    "    # 1-of-N encoding\n",
    "    outputs = np.argmax(outputs,1)\n",
    "    targets = np.argmax(targets,1)\n",
    "\n",
    "\n",
    "print(classification_report(targets, outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Iteration:  0  Error:  171.34742384282475\n",
      "Iteration:  100  Error:  342.9999986814771\n",
      "Iteration:  200  Error:  342.99999867933263\n",
      "Iteration:  300  Error:  342.99999867680503\n",
      "Iteration:  400  Error:  342.9999986742679\n",
      "Iteration:  500  Error:  342.9999986717212\n",
      "Iteration:  600  Error:  342.99999866916494\n",
      "Iteration:  700  Error:  342.9999986665989\n",
      "Iteration:  800  Error:  342.99999866402334\n",
      "Iteration:  900  Error:  342.99999866143787\n",
      "Iteration:  1000  Error:  342.9999986588426\n",
      "Iteration:  1100  Error:  342.9999986562375\n",
      "Iteration:  1200  Error:  342.99999865362247\n",
      "Iteration:  1300  Error:  342.99999865099744\n",
      "Iteration:  1400  Error:  342.99999864836235\n",
      "Iteration:  1500  Error:  342.99999864571714\n",
      "Iteration:  1600  Error:  342.9999986430619\n",
      "Iteration:  1700  Error:  342.99999864039626\n",
      "Iteration:  1800  Error:  342.99999863772047\n",
      "Iteration:  1900  Error:  342.9999986350342\n",
      "Iteration:  2000  Error:  342.9999986323377\n",
      "Iteration:  2100  Error:  342.9999986296306\n",
      "Iteration:  2200  Error:  342.9999986269131\n",
      "Iteration:  2300  Error:  342.99999862418497\n",
      "Iteration:  2400  Error:  342.99999862144614\n",
      "Iteration:  2500  Error:  342.99999861869674\n",
      "Iteration:  2600  Error:  342.9999986159365\n",
      "Iteration:  2700  Error:  342.9999986131654\n",
      "Iteration:  2800  Error:  342.9999986103835\n",
      "Iteration:  2900  Error:  342.9999986075906\n",
      "Iteration:  3000  Error:  342.9999986047867\n",
      "Iteration:  3100  Error:  342.9999986019717\n",
      "Iteration:  3200  Error:  342.99999859914556\n",
      "Iteration:  3300  Error:  342.99999859630816\n",
      "Iteration:  3400  Error:  342.99999859345957\n",
      "Iteration:  3500  Error:  342.99999859059955\n",
      "Iteration:  3600  Error:  342.99999858772816\n",
      "Iteration:  3700  Error:  342.9999985848453\n",
      "Iteration:  3800  Error:  342.9999985819509\n",
      "Iteration:  3900  Error:  342.9999985790448\n",
      "Iteration:  4000  Error:  342.99999857612704\n",
      "Iteration:  4100  Error:  342.99999857319756\n",
      "Iteration:  4200  Error:  342.99999857025625\n",
      "Iteration:  4300  Error:  342.999998567303\n",
      "Iteration:  4400  Error:  342.99999856433783\n",
      "Iteration:  4500  Error:  342.9999985613606\n",
      "Iteration:  4600  Error:  342.9999985583712\n",
      "Iteration:  4700  Error:  342.99999855536964\n",
      "Iteration:  4800  Error:  342.99999855235586\n",
      "Iteration:  4900  Error:  342.9999985493297\n",
      "2\n",
      "Iteration:  0  Error:  342.9999985462912\n",
      "Iteration:  100  Error:  342.99999854351506\n",
      "Iteration:  200  Error:  342.99999854045257\n",
      "Iteration:  300  Error:  342.99999853737745\n",
      "Iteration:  400  Error:  342.9999985342896\n",
      "Iteration:  500  Error:  342.9999985311889\n",
      "Iteration:  600  Error:  342.9999985280754\n",
      "Iteration:  700  Error:  342.999998524949\n",
      "Iteration:  800  Error:  342.9999985218094\n",
      "Iteration:  900  Error:  342.99999851865687\n",
      "Iteration:  1000  Error:  342.999998515491\n",
      "Iteration:  1100  Error:  342.9999985123119\n",
      "Iteration:  1200  Error:  342.99999850911945\n",
      "Iteration:  1300  Error:  342.9999985059136\n",
      "Iteration:  1400  Error:  342.99999850269415\n",
      "Iteration:  1500  Error:  342.99999849946107\n",
      "Iteration:  1600  Error:  342.9999984962143\n",
      "Iteration:  1700  Error:  342.9999984929538\n",
      "Iteration:  1800  Error:  342.9999984896794\n",
      "Iteration:  1900  Error:  342.99999848639106\n",
      "Iteration:  2000  Error:  342.99999848308863\n",
      "Iteration:  2100  Error:  342.99999847977205\n",
      "Iteration:  2200  Error:  342.9999984764413\n",
      "Iteration:  2300  Error:  342.9999984730962\n",
      "Iteration:  2400  Error:  342.9999984697366\n",
      "Iteration:  2500  Error:  342.9999984663626\n",
      "Iteration:  2600  Error:  342.99999846297396\n",
      "Iteration:  2700  Error:  342.9999984595707\n",
      "Iteration:  2800  Error:  342.9999984561526\n",
      "Iteration:  2900  Error:  342.9999984527195\n",
      "Iteration:  3000  Error:  342.9999984492715\n",
      "Iteration:  3100  Error:  342.9999984458085\n",
      "Iteration:  3200  Error:  342.99999844233025\n",
      "Iteration:  3300  Error:  342.99999843883677\n",
      "Iteration:  3400  Error:  342.9999984353278\n",
      "Iteration:  3500  Error:  342.99999843180353\n",
      "Iteration:  3600  Error:  342.99999842826355\n",
      "Iteration:  3700  Error:  342.999998424708\n",
      "Iteration:  3800  Error:  342.9999984211365\n",
      "Iteration:  3900  Error:  342.99999841754925\n",
      "Iteration:  4000  Error:  342.99999841394595\n",
      "Iteration:  4100  Error:  342.99999841032655\n",
      "Iteration:  4200  Error:  342.9999984066909\n",
      "Iteration:  4300  Error:  342.99999840303906\n",
      "Iteration:  4400  Error:  342.99999839937067\n",
      "Iteration:  4500  Error:  342.9999983956858\n",
      "Iteration:  4600  Error:  342.99999839198426\n",
      "Iteration:  4700  Error:  342.99999838826596\n",
      "Iteration:  4800  Error:  342.9999983845308\n",
      "Iteration:  4900  Error:  342.99999838077866\n",
      "3\n",
      "Iteration:  0  Error:  342.99999837700943\n",
      "Iteration:  100  Error:  342.99999837356427\n",
      "Iteration:  200  Error:  342.9999983697621\n",
      "Iteration:  300  Error:  342.99999836594236\n",
      "Iteration:  400  Error:  342.99999836210515\n",
      "Iteration:  500  Error:  342.9999983582502\n",
      "Iteration:  600  Error:  342.9999983543775\n",
      "Iteration:  700  Error:  342.99999835048686\n",
      "Iteration:  800  Error:  342.99999834657814\n",
      "Iteration:  900  Error:  342.9999983426512\n",
      "Iteration:  1000  Error:  342.99999833870606\n",
      "Iteration:  1100  Error:  342.9999983347425\n",
      "Iteration:  1200  Error:  342.99999833076026\n",
      "Iteration:  1300  Error:  342.9999983267594\n",
      "Iteration:  1400  Error:  342.99999832273977\n",
      "Iteration:  1500  Error:  342.9999983187011\n",
      "Iteration:  1600  Error:  342.99999831464345\n",
      "Iteration:  1700  Error:  342.9999983105665\n",
      "Iteration:  1800  Error:  342.9999983064702\n",
      "Iteration:  1900  Error:  342.99999830235447\n",
      "Iteration:  2000  Error:  342.999998298219\n",
      "Iteration:  2100  Error:  342.9999982940639\n",
      "Iteration:  2200  Error:  342.9999982898888\n",
      "Iteration:  2300  Error:  342.9999982856937\n",
      "Iteration:  2400  Error:  342.99999828147844\n",
      "Iteration:  2500  Error:  342.99999827724275\n",
      "Iteration:  2600  Error:  342.9999982729866\n",
      "Iteration:  2700  Error:  342.9999982687099\n",
      "Iteration:  2800  Error:  342.9999982644123\n",
      "Iteration:  2900  Error:  342.99999826009383\n",
      "Iteration:  3000  Error:  342.99999825575424\n",
      "Iteration:  3100  Error:  342.99999825139344\n",
      "Iteration:  3200  Error:  342.99999824701126\n",
      "Iteration:  3300  Error:  342.9999982426075\n",
      "Iteration:  3400  Error:  342.999998238182\n",
      "Iteration:  3500  Error:  342.9999982337347\n",
      "Iteration:  3600  Error:  342.9999982292653\n",
      "Iteration:  3700  Error:  342.9999982247739\n",
      "Iteration:  3800  Error:  342.99999822025995\n",
      "Iteration:  3900  Error:  342.9999982157235\n",
      "Iteration:  4000  Error:  342.9999982111644\n",
      "Iteration:  4100  Error:  342.9999982065824\n",
      "Iteration:  4200  Error:  342.9999982019774\n",
      "Iteration:  4300  Error:  342.9999981973492\n",
      "Iteration:  4400  Error:  342.9999981926976\n",
      "Iteration:  4500  Error:  342.9999981880226\n",
      "Iteration:  4600  Error:  342.99999818332367\n",
      "Iteration:  4700  Error:  342.99999817860095\n",
      "Iteration:  4800  Error:  342.9999981738541\n",
      "Iteration:  4900  Error:  342.9999981690829\n",
      "Stopped 171.4999989582236 171.49999907941526 171.49999917581596\n",
      "Confusion matrix is:\n",
      "[[191. 152.]\n",
      " [  0.   0.]]\n",
      "Percentage Correct:  55.68513119533528\n"
     ]
    }
   ],
   "source": [
    "import MLP as mlp \n",
    "net =mlp.mlp(train,traint,20,outtype='logistic')\n",
    "net.earlystopping(train,traint,valid,validt,0.1)\n",
    "cm=net.confmat(test,testt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      1.00      0.72       191\n",
      "           1       0.00      0.00      0.00       152\n",
      "\n",
      "    accuracy                           0.56       343\n",
      "   macro avg       0.28      0.50      0.36       343\n",
      "weighted avg       0.31      0.56      0.40       343\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mona/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "targets=testt\n",
    "inputs=np.concatenate((test,-np.ones((np.shape(test)[0],1))),axis=1)\n",
    "nclasses=np.shape(targets)[1]\n",
    "output=net.mlpfwd(inputs)\n",
    "if nclasses==1:\n",
    "    nclasses=2\n",
    "    output=np.where(output>0.5,1,0)\n",
    "else:\n",
    "    output=np.argmax(output,1)\n",
    "    targets=np.argmax(targets,1)\n",
    "   \n",
    "print(classification_report(targets,output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
